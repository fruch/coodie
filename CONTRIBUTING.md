# Contributing

Contributions are welcome, and they are greatly appreciated! Every little helps, and credit will always be given.

You can contribute in many ways:

## Types of Contributions

### Report Bugs

Report bugs to [our issue page][gh-issues]. If you are reporting a bug, please include:

- Your operating system name and version.
- Any details about your local setup that might be helpful in troubleshooting.
- Detailed steps to reproduce the bug.

### Fix Bugs

Look through the GitHub issues for bugs. Anything tagged with "bug" and "help wanted" is open to whoever wants to implement it.

### Implement Features

Look through the GitHub issues for features. Anything tagged with "enhancement" and "help wanted" is open to whoever wants to implement it.

### Write Documentation

coodie could always use more documentation, whether as part of the official coodie docs, in docstrings, or even on the web in blog posts, articles, and such.

### Submit Feedback

The best way to send feedback [our issue page][gh-issues] on GitHub. If you are proposing a feature:

- Explain in detail how it would work.
- Keep the scope as narrow as possible, to make it easier to implement.
- Remember that this is a volunteer-driven project, and that contributions are welcome ðŸ˜Š

## Get Started!

Ready to contribute? Here's how to set yourself up for local development.

### Prerequisites

- **Python 3.10+**
- **[uv](https://github.com/astral-sh/uv)** (recommended) or pip
- **Docker** (for integration tests)

### Quick Setup

```bash
# Fork & clone
git clone git@github.com:your_name_here/coodie.git
cd coodie

# Install dependencies with uv (recommended)
uv sync --all-extras

# Install bats for workflow shell script tests (optional)
# macOS:  brew install bats-core
# Ubuntu: sudo apt-get install bats
# Or from source: https://bats-core.readthedocs.io/en/stable/installation.html

# Or with pip
pip install -e ".[scylla]"
pip install pytest pytest-cov pytest-asyncio pre-commit

# Install pre-commit hooks
uv run pre-commit install

# Run unit tests (no database needed)
uv run pytest tests/ -v

# Run linters
uv run ruff check src/ tests/
uv run ruff format --check src/ tests/

# Lint GitHub Actions workflows
# (requires actionlint: https://github.com/rhysd/actionlint)
actionlint

# Or run all pre-commit hooks at once (includes actionlint)
uv run pre-commit run --all-files
```

### Running Integration Tests

Integration tests need a running ScyllaDB instance. The test suite uses
[testcontainers](https://github.com/testcontainers/testcontainers-python)
to start one automatically:

```bash
# Run integration tests (starts ScyllaDB via Docker)
uv run pytest tests/ -v -m integration
```

### Creating a Branch

```bash
git checkout -b name-of-your-bugfix-or-feature
```

Now you can make your changes locally.

### Committing

Commit messages must follow [Conventional Commits](https://www.conventionalcommits.org):

```bash
git add .
git commit -m "feat(something): your detailed description of your changes"
git push origin name-of-your-bugfix-or-feature
```

Examples:

- `feat(aio): add TTL support to Document.save()`
- `fix(cql_builder): escape column names with reserved words`
- `docs: update quickstart guide`
- `test(sync): add QuerySet chaining coverage`

We run [`commitlint` on CI](https://github.com/marketplace/actions/commit-linter) to validate commit messages. If you've installed pre-commit hooks, the message will be checked at commit time.

### Submitting a Pull Request

Submit a pull request through the GitHub website or using the GitHub CLI:

```bash
gh pr create --fill
```

## Pull Request Guidelines

We like to have the pull request open as soon as possible, that's a great place to discuss any piece of work, even unfinished. You can use draft pull request if it's still a work in progress. Here are a few guidelines to follow:

1. Include tests for feature or bug fixes.
2. Update the documentation for significant features.
3. Ensure tests are passing on CI.

### Slash Commands

Maintainers and collaborators with write access can use slash-commands in PR
comments to automate branch maintenance:

| Command | Effect |
|---|---|
| `/rebase` | Rebase the PR branch onto the base branch. If conflicts arise, the workflow attempts to resolve them with GitHub Copilot CLI. |
| `/squash` | Squash all PR commits into a single commit. The commit message is generated by Copilot CLI following [Conventional Commits](https://www.conventionalcommits.org/) format, with a generic fallback if Copilot is unavailable. |
| `/rebase squash` | Rebase first, then squash (combines both operations in one run). |

After each operation the workflow posts a summary comment on the PR. A ðŸš€
reaction is added on success, or ðŸ˜• on failure.

The workflow can also be triggered manually from the **Actions** tab â†’ **PR
Rebase & Squash** â†’ **Run workflow**, where you enter a PR number and select
the command. This is useful for testing or when the comment trigger is not
available.

> **When to use `/rebase` vs `/squash`:** Use `/rebase` when your branch is
> behind the base branch and you want to bring it up to date while preserving
> individual commits. Use `/squash` when the PR has many small or
> work-in-progress commits and you want a clean single-commit history before
> merging. Use `/rebase squash` to do both at once.

### Testing the Rebase & Squash Workflow Locally

#### Unit tests for the conflict-resolution script (fast, no Docker)

The conflict-resolution logic lives in `.github/scripts/resolve-conflicts.sh`
and is covered by Bats tests in `tests/workflows/test_resolve_conflicts.bats`.
Run them directly with `bats` or via `pytest`:

```bash
# Install bats-core once (macOS or Debian/Ubuntu)
brew install bats-core        # macOS
# apt install bats            # Ubuntu

# Run the Bats tests directly
bats tests/workflows/test_resolve_conflicts.bats

# Or run all workflow tests through pytest (unified reporting)
uv run pytest tests/workflows/ -v
```

#### End-to-end smoke test via `workflow_dispatch` (recommended, no Docker)

The workflow has a `workflow_dispatch` trigger so you can run it manually
against a real PR without posting a comment:

```bash
# Trigger rebase on PR #<N>
gh workflow run pr-rebase-squash.yml \
  --field pr_number=<N> \
  --field command=rebase

# Trigger squash
gh workflow run pr-rebase-squash.yml \
  --field pr_number=<N> \
  --field command=squash

# Rebase then squash in one run
gh workflow run pr-rebase-squash.yml \
  --field pr_number=<N> \
  --field "command=rebase squash"

# Watch the run live
gh run watch
```

#### Running with `act` (requires Docker)

[`act`](https://github.com/nektos/act) can simulate the `issue_comment`
trigger locally. Note that steps calling `gh api` require a real
`GITHUB_TOKEN` pointing at a live PR â€” `act` cannot mock GitHub API state.

```bash
# Install act (macOS or Linux)
brew install act     # macOS
# or: curl -s https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash

# Create a mock event payload (replace PR_NUMBER and COMMENT_ID)
cat > /tmp/rebase-event.json << 'EOF'
{
  "action": "created",
  "issue": {
    "number": PR_NUMBER,
    "pull_request": {"url": "https://api.github.com/repos/fruch/coodie/pulls/PR_NUMBER"}
  },
  "comment": {
    "id": COMMENT_ID,
    "body": "/rebase",
    "user": {"login": "fruch", "id": 340979}
  },
  "repository": {"full_name": "fruch/coodie", "name": "coodie",
                  "owner": {"login": "fruch"}}
}
EOF

# Run the workflow (the -P flag maps ubuntu-latest to a smaller act image)
act issue_comment \
  -e /tmp/rebase-event.json \
  --secret GITHUB_TOKEN="$(gh auth token)" \
  --secret COPILOT_PAT="$(gh auth token)" \
  -W .github/workflows/pr-rebase-squash.yml \
  --job rebase-squash \
  -P ubuntu-latest=catthehacker/ubuntu:act-22.04
```

> **Tip:** The `workflow_dispatch` approach is preferred for end-to-end
> testing because it uses the real GitHub API and avoids the Docker overhead.
> Use `act` when you need to iterate on workflow logic without consuming
> GitHub Actions minutes.

## Tips

To run a subset of tests:

```bash
uv run pytest tests/ -k "test_something" -v
```

## Workflow Testing

The repository's GitHub Actions workflows are tested at three levels:

1. **Static Analysis** â€” [`actionlint`](https://github.com/rhysd/actionlint) runs via pre-commit (which CI also runs) to catch YAML and expression errors.
2. **Shell Script Unit Tests** â€” Complex shell logic is extracted into `.github/scripts/` and tested with [Bats](https://github.com/bats-core/bats-core). A custom pytest-bats plugin (`tests/workflows/conftest.py`) collects `.bats` files as pytest items, so they run alongside regular Python tests:
   ```bash
   # Direct (requires bats installed)
   bats tests/workflows/

   # Via pytest (the conftest.py plugin runs each @test block as a pytest item;
   # skips gracefully if bats is not installed)
   uv run pytest tests/workflows/ -v
   ```
3. **Convention Checks** â€” `tests/test_workflow_conventions.py` enforces project-level rules (pinned actions, concurrency groups, `GH_TOKEN`, etc.) via pytest.

### Manual Smoke Tests (workflow_dispatch)

The `PR Rebase & Squash` and `Self-Healing CI` workflows support `workflow_dispatch` triggers for manual testing:

1. Go to **Actions** â†’ select the workflow â†’ **Run workflow**.
2. For `PR Rebase & Squash`: enter a PR number and select the command (`rebase`, `squash`, or `rebase squash`).
3. For `Self-Healing CI`: enter a workflow run ID to inspect.
4. Verify the expected comment is posted on the PR.
5. **Cleanup:** If the operation modified the PR branch (rebase/squash), restore it with `git reflog` and `git push --force-with-lease`.

## Making a new release

Publishing to PyPI is triggered automatically whenever a tag matching `v<major>.<minor>.<patch>` (e.g. `v1.0.0`) is pushed to the repository. The [Publish to PyPI](.github/workflows/publish.yml) GitHub Actions workflow will build the package and publish it using [Trusted Publishing](#setting-up-trusted-publishing-on-pypi) â€” no API tokens or credentials are stored in GitHub secrets.

### Setting up Trusted Publishing on PyPI

[Trusted Publishing](https://docs.pypi.org/trusted-publishers/) lets PyPI verify GitHub Actions runs via OpenID Connect (OIDC), so you never have to create or rotate a PyPI API token.

**One-time setup steps (done once per PyPI project):**

1. Go to <https://pypi.org> and log in.
2. Open the project page for `coodie`, then go to **Manage â†’ Publishing**.
   - If the project does not exist yet, go to <https://pypi.org/manage/account/publishing/> to add a *pending* publisher before the first upload.
3. Click **Add a new publisher** and fill in the form:

   | Field | Value |
   |---|---|
   | Owner | `fruch` |
   | Repository name | `coodie` |
   | Workflow name | `publish.yml` |
   | Environment name | `release` |

4. Click **Add**.

**GitHub repository setup:**

1. In the repository, go to **Settings â†’ Environments** and create an environment named **`release`**.
2. Optionally add protection rules (e.g. require a reviewer before the publish job runs).

Once this is done, pushing a version tag such as `v1.0.0` will trigger the workflow and PyPI will accept the upload without any stored credentials.

[gh-issues]: https://github.com/fruch/coodie/issues
