# Performance Improvement Plan for coodie

> **Based on**: Benchmark CI run [#22353872673](https://github.com/fruch/coodie/actions/runs/22353872673) â€” scylla driver ([job](https://github.com/fruch/coodie/actions/runs/22353872673/job/64694559794?pr=31#step:5:122)) and acsylla driver ([job](https://github.com/fruch/coodie/actions/runs/22353872673/job/64694559911?pr=31#step:5:122))
> **Date**: 2026-02-24
> **Status**: Updated with latest benchmark results and cross-driver comparison

---

## 1. Benchmark Summary (scylla driver)

### 1.1 Where coodie is faster (Pydantic advantage)

| Operation | coodie | cqlengine | Ratio | Notes |
|-----------|--------|-----------|-------|-------|
| Model instantiation | 2.00 Âµs | 11.58 Âµs | **0.17Ã— (5.8Ã— faster)** | Pydantic compiled validators |
| Model serialization | 2.01 Âµs | 4.60 Âµs | **0.44Ã— (2.3Ã— faster)** | `model_dump()` vs cqlengine internals |
| Argus model instantiation (11 fields) | 18.2 Âµs | 33.4 Âµs | **0.55Ã— (1.8Ã— faster)** | Pydantic scales better with field count |
| Batch INSERT 100 rows | 28.6 ms | 53.2 ms | **0.54Ã— (1.9Ã— faster)** | coodie batch CQL builder is more efficient |

### 1.2 Where coodie is slower (ORM overhead)

| Operation | coodie | cqlengine | Ratio | Severity |
|-----------|--------|-----------|-------|----------|
| `sync_table` no-op | 3,827 Âµs | 224 Âµs | **17.1Ã— slower** | ğŸ”´ Critical |
| `sync_table` create | 2,646 Âµs | 173 Âµs | **15.3Ã— slower** | ğŸ”´ Critical |
| Filter (secondary index) | 18.1 ms | 4.5 ms | **4.0Ã— slower** | ğŸ”´ Critical |
| Partial UPDATE | 2,203 Âµs | 508 Âµs | **4.3Ã— slower** | ğŸ”´ Critical |
| Filter + LIMIT | 3.06 ms | 1.12 ms | **2.7Ã— slower** | ğŸŸ  High |
| GET by PK | 1,382 Âµs | 651 Âµs | **2.1Ã— slower** | ğŸŸ  High |
| Collection read | 1,405 Âµs | 654 Âµs | **2.1Ã— slower** | ğŸŸ  High |
| UPDATE IF condition (LWT) | 3.34 ms | 1.64 ms | **2.0Ã— slower** | ğŸŸ  High |
| Batch INSERT 10 rows | 3.38 ms | 1.67 ms | **2.0Ã— slower** | ğŸŸ  High |
| Collection roundtrip | 2.46 ms | 1.30 ms | **1.89Ã— slower** | ğŸŸ¡ Medium |
| Single DELETE | 1.97 ms | 1.04 ms | **1.89Ã— slower** | ğŸŸ¡ Medium |
| Single INSERT | 1,025 Âµs | 589 Âµs | **1.74Ã— slower** | ğŸŸ¡ Medium |
| Bulk DELETE | 2.01 ms | 1.17 ms | **1.72Ã— slower** | ğŸŸ¡ Medium |
| INSERT with TTL | 1,016 Âµs | 621 Âµs | **1.64Ã— slower** | ğŸŸ¡ Medium |
| Collection write | 1,015 Âµs | 627 Âµs | **1.62Ã— slower** | ğŸŸ¡ Medium |
| COUNT | 1.49 ms | 1.02 ms | **1.47Ã— slower** | ğŸŸ¢ Acceptable |
| INSERT IF NOT EXISTS | 2.20 ms | 1.69 ms | **1.30Ã— slower** | ğŸŸ¢ Acceptable |

### 1.3 Argus-inspired real-world patterns (scylla driver)

| Pattern | coodie | cqlengine | Ratio | Notes |
|---------|--------|-----------|-------|-------|
| Notification feed | 1.43 ms | 1.35 ms | **1.06Ã—** | ğŸŸ¢ Near parity |
| Comment with collections | 779 Âµs | 751 Âµs | **1.04Ã—** | ğŸŸ¢ Near parity |
| Batch events (10) | 3.56 ms | 3.04 ms | **1.17Ã—** | ğŸŸ¢ Acceptable |
| Get-or-create user | 902 Âµs | 747 Âµs | **1.21Ã—** | ğŸŸ¢ Acceptable |
| Latest N runs (clustering) | 1,188 Âµs | 928 Âµs | **1.28Ã—** | ğŸŸ¢ Acceptable |
| Filter by partition key | 1.43 ms | 1.07 ms | **1.34Ã—** | ğŸŸ¢ Acceptable |
| Multi-model lookup | 1.81 ms | 1.32 ms | **1.37Ã—** | ğŸŸ¡ Medium |
| Status update (read-modify-save) | 1,752 Âµs | 836 Âµs | **2.10Ã—** | ğŸŸ  High |
| List mutation + save | 1,647 Âµs | 758 Âµs | **2.17Ã—** | ğŸŸ  High |

---

## 2. Root Cause Analysis

### 2.1 `_rows_to_dicts()` is the dominant bottleneck

Every query goes through `CassandraDriver._rows_to_dicts()` which iterates over
each row and converts it to a `dict`. This happens even when the driver already
returns Named Tuples (the default `row_factory`).

**Cost per row**: `hasattr` check + `_asdict()` call + `dict()` wrapping.

For queries returning N rows, this is O(N) dict allocations *before* Pydantic
even starts constructing model instances. cqlengine avoids this by working
directly with the driver's native row objects.

**Impact**: Affects every read operation â€” GET, filter, collection read, count.

### 2.2 `sync_table` always executes 3+ CQL queries

On every no-op `sync_table` call, coodie:
1. Executes `CREATE TABLE IF NOT EXISTS` (even if the table exists)
2. Queries `system_schema.columns` to detect missing columns
3. Scans all columns for index creation

cqlengine caches table metadata and skips the DDL if the table is already known.
coodie has no caching â€” every `sync_table` call hits the database.

### 2.3 `build_schema()` re-runs `get_type_hints()` on every write

`Document.save()` calls `_schema()` which calls `build_schema()`. Although there's
a cache check (`__schema__`), `_find_discriminator_column()` and
`_get_discriminator_value()` are called on every `save()` operation, each calling
`get_type_hints()` which is expensive (involves `typing` module introspection).

### 2.4 No CQL query caching at the QuerySet level

Each `QuerySet.all()`, `first()`, `get()`, etc. calls `build_select()` which
constructs a new CQL string via f-string interpolation every time. The same
logical query (e.g., "get product by id") builds the same CQL string repeatedly.

### 2.5 `get_driver()` function-level import on every call

`get_driver()` is called from inside method bodies, which means Python re-evaluates
the `from coodie.drivers import get_driver` import statement on every call.
While cached by Python's import system, the import machinery lookup has non-zero
cost at high call frequency.

### 2.6 Quadratic column scan in `sync_table`

The `sync_table` method iterates over all columns twice: once to check for missing
columns (`if col.name not in existing`) and once to check for indexes
(`if col.index`). For N columns, this is 2Ã—N iterations plus an O(N) set lookup per
column.

---

## 3. Improvement Plan

### Phase 1 â€” Quick wins (estimated 30-50% improvement on reads)

#### 3.1 Optimize `_rows_to_dicts()` by type-checking once

**Current**: checks `hasattr(row, "_asdict")` for *every* row.
**Proposed**: Check the first row's type, then use the appropriate fast path
for all remaining rows.

```python
def _rows_to_dicts(result_set):
    if not result_set:
        return []
    rows = list(result_set)
    if not rows:
        return []
    sample = rows[0]
    if hasattr(sample, "_asdict"):
        return [dict(r._asdict()) for r in rows]
    elif isinstance(sample, dict):
        return rows  # already dicts â€” zero-copy!
    else:
        return [{k: v for k, v in r.__dict__.items() if not k.startswith("_")} for r in rows]
```

**Estimated impact**: ~20-30% faster reads when `dict_factory` is in use (zero-copy);
~10% faster for Named Tuple rows (no per-row `hasattr`).

#### 3.2 Cache discriminator metadata per class

Cache the discriminator column name and value as class-level attributes after first
computation:

```python
@classmethod
def _cached_disc_info(cls):
    if not hasattr(cls, "_disc_col_cache"):
        cls._disc_col_cache = _find_discriminator_column(cls)
        cls._disc_val_cache = _get_discriminator_value(cls)
    return cls._disc_col_cache, cls._disc_val_cache
```

**Estimated impact**: Eliminates `get_type_hints()` on every `save()`/`insert()` call.
~10-15% faster writes for non-polymorphic models.

#### 3.3 Move `from coodie.drivers import get_driver` to module level

Replace function-level imports of `get_driver` with a module-level import
(guarded by lazy initialization if needed to avoid circular imports).

**Estimated impact**: Marginal per-call (~1-5%), but compounds across all operations.

### Phase 2 â€” `sync_table` optimization (target: â‰¤ 2Ã— cqlengine)

#### 3.4 Add table metadata cache to `CassandraDriver`

```python
class CassandraDriver:
    def __init__(self, ...):
        ...
        self._known_tables: set[str] = set()

    def sync_table(self, table, keyspace, cols, ...):
        cache_key = f"{keyspace}.{table}"
        if cache_key in self._known_tables:
            return  # table already synced this session
        # ... existing DDL logic ...
        self._known_tables.add(cache_key)
```

**Estimated impact**: Reduces `sync_table` no-op from 4,199 Âµs to ~0 Âµs (cache hit).
This alone closes the 18Ã— gap.

#### 3.5 Use `CREATE TABLE IF NOT EXISTS` result to skip column introspection

If the `CREATE TABLE` succeeds (table was just created), skip the
`_get_existing_columns()` query since all columns are known to be present.

**Estimated impact**: Reduces first-run `sync_table` from 3 queries to 1.

### Phase 3 â€” Query path optimization (target: â‰¤ 1.5Ã— cqlengine for reads)

#### 3.6 Build CQL for `model_dump()` directly, skipping intermediate dict

For `save()`/`insert()`, the current flow is:
```
model â†’ model_dump() â†’ dict â†’ build_insert(dict) â†’ CQL string
```

Optimize to:
```
model â†’ build_insert_from_model(model) â†’ CQL string
```

This avoids creating an intermediate dict for every write.

**Estimated impact**: ~15% faster writes.

#### 3.7 Construct Pydantic models from driver rows without intermediate dict

For reads, the current flow is:
```
driver rows â†’ _rows_to_dicts() â†’ list[dict] â†’ [Model(**dict) for dict] â†’ list[Model]
```

Optimize by passing `model_validate()` directly:
```
driver rows â†’ [Model.model_validate(row) for row] â†’ list[Model]
```

Pydantic's `model_validate()` can accept Named Tuples and mappings directly.

**Estimated impact**: Eliminates dict allocation per row. ~20-30% faster reads.

#### 3.8 Cache CQL query strings in QuerySet

For the common case of `Model.objects.filter(id=uuid).get()`, the CQL query
string is always `SELECT ... FROM ks.table WHERE "id" = ?`. Cache this:

```python
class QuerySet:
    _cql_cache: ClassVar[dict[tuple, tuple[str, list]]] = {}
```

**Estimated impact**: Eliminates f-string CQL construction on repeat queries.
~5-10% faster for repeated query patterns.

### Phase 4 â€” Filter path optimization (target: â‰¤ 2Ã— for filtered queries)

#### 3.9 Optimize `parse_filter_kwargs()` string splitting

The current filter parsing splits kwargs on `__` to detect operators. This involves
string manipulation for every filter keyword argument. Pre-compile common patterns.

#### 3.10 Reduce `QuerySet._clone()` overhead

Every chained call (`.filter().limit().allow_filtering()`) creates a new `QuerySet`
instance. Each clone copies all parameters. Consider using a builder pattern that
mutates in place until a terminal method is called.

**Estimated impact**: ~10-15% faster for complex chained queries.

### Phase 5 â€” Async optimization

#### 3.11 Eliminate `run_in_executor` for CassandraDriver async path

The current async implementation uses `run_in_executor` to delegate to the sync
`execute()`. This adds thread-pool overhead. Instead, use the cassandra-driver's
native async `execute_async()` with proper callback handling.

**Estimated impact**: ~20-40% faster async operations (eliminates thread pool hop).

---

## 4. Priority Matrix

| Phase | Task | Effort | Impact | Priority |
|-------|------|--------|--------|----------|
| 1 | 3.1 Optimize `_rows_to_dicts()` | Small | High | **P0** |
| 1 | 3.2 Cache discriminator metadata | Small | Medium | **P0** |
| 2 | 3.4 Table metadata cache | Small | Critical | **P0** |
| 1 | 3.3 Module-level `get_driver` import | Small | Low | P1 |
| 2 | 3.5 Skip column introspection on create | Medium | Medium | P1 |
| 3 | 3.7 Skip intermediate dict on reads | Medium | High | **P1** |
| 3 | 3.6 Skip intermediate dict on writes | Medium | Medium | P1 |
| 3 | 3.8 CQL query string cache | Medium | Low | P2 |
| 4 | 3.10 Reduce `_clone()` overhead | Medium | Medium | P2 |
| 4 | 3.9 Pre-compile filter patterns | Small | Low | P2 |
| 5 | 3.11 Native async for CassandraDriver | Large | High | P2 |

---

## 5. Success Criteria

After implementing P0 and P1 items:

| Metric | Current | Target |
|--------|---------|--------|
| Single INSERT latency | 1.72Ã— cqlengine | â‰¤ 1.3Ã— |
| GET by PK latency | 2.13Ã— cqlengine | â‰¤ 1.5Ã— |
| Filter + LIMIT latency | 2.66Ã— cqlengine | â‰¤ 1.8Ã— |
| `sync_table` no-op | 18Ã— cqlengine | â‰¤ 1.5Ã— |
| Partial UPDATE | 4.22Ã— cqlengine | â‰¤ 2Ã— |
| Model instantiation | 0.17Ã— cqlengine | â‰¤ 0.2Ã— (maintain advantage) |
| Model serialization | 0.43Ã— cqlengine | â‰¤ 0.5Ã— (maintain advantage) |

---

## 6. Measurement

All improvements must be validated with the benchmark suite:

```bash
# Save current baseline
pytest benchmarks/ --benchmark-enable --benchmark-save=pre-optimization

# After changes
pytest benchmarks/ --benchmark-enable --benchmark-compare=0001_pre-optimization
```

Regressions in any benchmark > 5% must be investigated before merging.

---

## 7. General Speed Improvements

Beyond the operation-specific optimizations above, several cross-cutting techniques
can improve coodie's overall throughput and memory efficiency.

### 7.1 `__slots__` on internal classes

**Where**: `QuerySet`, `ColumnDefinition`, `PagedResult`, `LWTResult`, driver classes.

Python's `__slots__` eliminates the per-instance `__dict__`, which reduces memory
by ~40-60 bytes per object and speeds up attribute access by ~10-20%.

```python
# QuerySet â€” created on every chained call (.filter().limit().all())
class QuerySet:
    __slots__ = (
        "_doc_cls", "_where", "_limit_val", "_order_by_val",
        "_allow_filtering_val", "_if_not_exists_val", "_if_exists_val",
        "_ttl_val", "_timestamp_val", "_consistency_val", "_timeout_val",
        "_only_val", "_defer_val", "_values_list_val",
        "_per_partition_limit_val", "_fetch_size_val", "_paging_state_val",
    )
```

`QuerySet` is the highest-impact target â€” every chained method (`.filter()`,
`.limit()`, `.all()`) creates a new instance via `_clone()`. Removing `__dict__`
overhead on each clone directly speeds up query chains.

`ColumnDefinition` is already a `@dataclass` â€” adding `@dataclass(slots=True)`
(Python 3.10+) or `__slots__` eliminates dict overhead for schema introspection.

**Note**: Pydantic v2 `BaseModel` does **not** support `__slots__` on the model
itself (it uses its own `__dict__` for field storage). However, the internal
`model_config = ConfigDict(...)` can be tuned (see Â§7.3).

**Estimated impact**: ~5-10% faster query chain construction, ~30% less memory for
large result sets (fewer `QuerySet` dicts in flight).

### 7.2 `__slots__` on driver classes

```python
class CassandraDriver(AbstractDriver):
    __slots__ = ("_session", "_default_keyspace", "_prepared", "_last_paging_state")
```

Driver instances are long-lived singletons, so memory savings are marginal. The
real benefit is faster attribute access on the hot path (`self._prepare()`,
`self._session.execute()`).

**Estimated impact**: ~2-5% faster per-operation driver access.

### 7.3 Pydantic `model_config` tuning

coodie's `Document` base class currently only sets `arbitrary_types_allowed = True`.
Additional Pydantic v2 config options can improve performance:

```python
class Document(BaseModel):
    model_config = ConfigDict(
        arbitrary_types_allowed=True,
        # Disable revalidation â€” trust data from Cassandra
        revalidate_instances="never",
        # Forbid extra fields â€” enables faster __init__
        extra="forbid",
        # Use enum values directly â€” skip .value conversion
        use_enum_values=True,
        # Populate by field name for direct dict construction
        populate_by_name=True,
    )
```

Key wins:
- **`revalidate_instances="never"`**: Skips re-validation when models are nested.
  coodie models are flat (no nested Documents), but this prevents accidental overhead.
- **`extra="forbid"`**: Pydantic can skip the "extra fields" check path entirely,
  making `__init__` faster.
- **`use_enum_values=True`**: Avoids `.value` attribute lookup for enum-typed fields.

**Estimated impact**: ~5-10% faster model construction from DB rows.

### 7.4 Lazy parsing for large documents (Beanie pattern)

Beanie ODM offers `lazy_parse=True` on queries, deferring Pydantic validation
until a field is actually accessed. This is highly effective for large documents
where only a few fields are read.

coodie could implement this via a `LazyDocument` proxy:

```python
class LazyDocument:
    """Proxy that defers Pydantic parsing until field access."""
    __slots__ = ("_doc_cls", "_raw_data", "_parsed")

    def __init__(self, doc_cls, raw_data):
        self._doc_cls = doc_cls
        self._raw_data = raw_data
        self._parsed = None

    def __getattr__(self, name):
        if self._parsed is None:
            self._parsed = self._doc_cls(**self._raw_data)
        return getattr(self._parsed, name)
```

Usage: `QuerySet.all(lazy=True)` returns `list[LazyDocument]` instead of
`list[Document]`, skipping Pydantic construction entirely until needed.

**Estimated impact**: Near-zero cost for queries where only PK fields are read
(common in exists-checks, pagination, or status dashboards).

### 7.5 LRU cache for `get_type_hints()` calls

`get_type_hints()` is called on every:
- `_find_discriminator_column()` â€” every `save()`, `find()`, `_rows_to_docs()`
- `coerce_row_none_collections()` â€” every row construction
- `build_schema()` â€” first call only (already cached)

Since type hints never change at runtime, cache the result:

```python
import functools

@functools.lru_cache(maxsize=128)
def _cached_type_hints(cls: type) -> dict[str, Any]:
    try:
        return typing.get_type_hints(cls, include_extras=True)
    except Exception:
        return getattr(cls, "__annotations__", {})
```

Then replace all `get_type_hints(cls, include_extras=True)` calls with
`_cached_type_hints(cls)`.

**Estimated impact**: Eliminates the #1 per-call overhead in `save()` and `find()`.
~15-25% faster for polymorphic models, ~5-10% for regular models (removes
`typing` module introspection on every call).

### 7.6 Projection support (Beanie pattern)

Beanie's `projection_model` returns only requested fields, reducing both network
transfer and parsing cost. coodie already has `.only("col1", "col2")` but still
constructs the full model.

Enhance with projection models:

```python
class ProductNameOnly(BaseModel):
    name: str
    price: float

# Returns list[ProductNameOnly] â€” lighter, faster
products = Product.objects.project(ProductNameOnly).all()
```

This avoids validating/defaulting unused fields entirely.

**Estimated impact**: 2-5Ã— faster for wide tables where only a few columns are needed.

### 7.7 Pre-compute collection coercion map per class

`coerce_row_none_collections()` currently calls `get_type_hints()` and scans
all annotations on **every row**. Pre-compute a set of collection-typed field names:

```python
@functools.lru_cache(maxsize=128)
def _collection_fields(cls: type) -> set[str]:
    """Return field names that have collection types (list, set, dict, tuple)."""
    hints = _cached_type_hints(cls)
    result = set()
    for name, ann in hints.items():
        base = _unwrap_annotation(ann)
        origin = typing.get_origin(base) or base
        if origin in (list, set, dict, tuple, frozenset):
            result.add(name)
    return result
```

Then coercion becomes a simple set lookup per row:

```python
def coerce_row_none_collections(doc_cls, row):
    for key in _collection_fields(doc_cls):
        if row.get(key) is None:
            row[key] = _COLLECTION_ORIGINS[...]()
    return row
```

**Estimated impact**: ~10-15% faster row construction for models with collections.

### 7.8 `model_validate()` instead of `**dict` construction

Pydantic v2's `model_validate()` accepts mappings directly and is optimized
internally (compiled Rust validators). Using it instead of `Model(**dict)`:

```python
# Current (slower)
self._doc_cls(**coerce_row_none_collections(self._doc_cls, row))

# Proposed (faster â€” Pydantic compiled path)
self._doc_cls.model_validate(coerce_row_none_collections(self._doc_cls, row))
```

**Estimated impact**: ~5-10% faster model construction (Pydantic's optimized path).

---

## 8. Updated Priority Matrix (including general improvements)

| Phase | Task | Effort | Impact | Priority |
|-------|------|--------|--------|----------|
| 1 | 3.1 Optimize `_rows_to_dicts()` | Small | High | **P0** |
| 1 | 3.2 Cache discriminator metadata | Small | Medium | **P0** |
| 2 | 3.4 Table metadata cache | Small | Critical | **P0** |
| 1 | 7.5 LRU cache for `get_type_hints()` | Small | High | **P0** |
| 1 | 7.7 Pre-compute collection coercion map | Small | Medium | **P0** |
| 1 | 7.1 `__slots__` on QuerySet | Small | Medium | **P1** |
| 1 | 7.3 Pydantic `model_config` tuning | Small | Medium | **P1** |
| 1 | 7.8 Use `model_validate()` | Small | Low-Med | **P1** |
| 1 | 3.3 Module-level `get_driver` import | Small | Low | P1 |
| 2 | 3.5 Skip column introspection on create | Medium | Medium | P1 |
| 3 | 3.7 Skip intermediate dict on reads | Medium | High | **P1** |
| 3 | 3.6 Skip intermediate dict on writes | Medium | Medium | P1 |
| 1 | 7.2 `__slots__` on driver classes | Small | Low | P2 |
| 3 | 3.8 CQL query string cache | Medium | Low | P2 |
| 4 | 3.10 Reduce `_clone()` overhead | Medium | Medium | P2 |
| 4 | 3.9 Pre-compile filter patterns | Small | Low | P2 |
| 5 | 3.11 Native async for CassandraDriver | Large | High | P2 |
| 3 | 7.4 Lazy parsing (LazyDocument) | Medium | High | P2 |
| 3 | 7.6 Projection model support | Medium | Medium | P2 |

---

## 9. Driver Comparison: scylla-driver vs acsylla

> **Run**: [#22353872673](https://github.com/fruch/coodie/actions/runs/22353872673) â€” same ScyllaDB container, same benchmark code, different coodie driver.
> cqlengine always uses scylla-driver regardless of the `--driver-type` option.

### 9.1 coodie performance by driver (Mean times)

| Operation | scylla-driver | acsylla | Î” | Winner |
|-----------|--------------|---------|---|--------|
| **DDL / Schema** | | | | |
| `sync_table` create | 2,646 Âµs | 1,345 Âµs | **âˆ’49%** | ğŸ† acsylla |
| `sync_table` no-op | 3,827 Âµs | 2,624 Âµs | **âˆ’31%** | ğŸ† acsylla |
| **Writes** | | | | |
| Single INSERT | 1,025 Âµs | 1,109 Âµs | +8% | scylla |
| INSERT with TTL | 1,016 Âµs | 1,113 Âµs | +10% | scylla |
| INSERT IF NOT EXISTS | 2,200 Âµs | 1,616 Âµs | **âˆ’27%** | ğŸ† acsylla |
| Collection write | 1,015 Âµs | 1,101 Âµs | +8% | scylla |
| **Reads** | | | | |
| GET by PK | 1,382 Âµs | 1,373 Âµs | ~0% | tie |
| Filter + LIMIT | 3,058 Âµs | 2,916 Âµs | âˆ’5% | acsylla |
| Filter (secondary index) | 18,120 Âµs | 18,843 Âµs | +4% | scylla |
| COUNT | 1,492 Âµs | 1,487 Âµs | ~0% | tie |
| Collection read | 1,405 Âµs | 1,402 Âµs | ~0% | tie |
| Collection roundtrip | 2,459 Âµs | 2,433 Âµs | ~0% | tie |
| **Updates** | | | | |
| Partial UPDATE | 2,203 Âµs | 2,253 Âµs | +2% | tie |
| UPDATE IF condition (LWT) | 3,342 Âµs | 2,931 Âµs | **âˆ’12%** | ğŸ† acsylla |
| **Deletes** | | | | |
| Single DELETE | 1,967 Âµs | 2,007 Âµs | +2% | tie |
| Bulk DELETE | 2,010 Âµs | 2,187 Âµs | +9% | scylla |
| **Batch** | | | | |
| Batch INSERT 10 | 3,379 Âµs | 3,374 Âµs | ~0% | tie |
| Batch INSERT 100 | 28,612 Âµs | 28,992 Âµs | ~0% | tie |
| **Serialization (no DB)** | | | | |
| Model instantiation | 2.00 Âµs | 2.03 Âµs | ~0% | tie |
| Model serialization | 2.01 Âµs | 1.94 Âµs | ~0% | tie |

### 9.2 Argus patterns by driver

| Pattern | scylla-driver | acsylla | Î” | Winner |
|---------|--------------|---------|---|--------|
| Get-or-create user | 902 Âµs | 905 Âµs | ~0% | tie |
| Filter by partition key | 1,429 Âµs | 1,418 Âµs | ~0% | tie |
| Latest N runs (clustering) | 1,188 Âµs | 1,245 Âµs | +5% | scylla |
| List mutation + save | 1,647 Âµs | 1,595 Âµs | âˆ’3% | acsylla |
| Batch events (10) | 3,557 Âµs | 3,534 Âµs | ~0% | tie |
| Notification feed | 1,433 Âµs | 1,393 Âµs | âˆ’3% | acsylla |
| Status update | 1,752 Âµs | 1,665 Âµs | âˆ’5% | acsylla |
| Comment with collections | 779 Âµs | 757 Âµs | âˆ’3% | acsylla |
| Multi-model lookup | 1,813 Âµs | 1,819 Âµs | ~0% | tie |
| Argus model instantiation | 18.2 Âµs | 18.3 Âµs | ~0% | tie |

### 9.3 Key Findings

1. **acsylla dominates DDL operations**: `sync_table` is 31â€“49% faster with acsylla.
   This is likely because acsylla's C++ core handles the CQL round-trips more
   efficiently than scylla-driver's Python-level protocol handling.

2. **acsylla wins on LWT/conditional writes**: INSERT IF NOT EXISTS is 27% faster,
   UPDATE IF is 12% faster. LWT operations involve extra coordinator round-trips
   where acsylla's native event loop outperforms scylla-driver's thread-pool model.

3. **scylla-driver is slightly faster for simple writes**: Single INSERT and INSERT
   with TTL are 8-10% faster with scylla-driver. The prepared-statement caching
   in scylla-driver's Python layer may avoid the async bridge overhead that acsylla
   pays when called from sync code.

4. **Read performance is identical**: GET by PK, COUNT, collection reads, and most
   Argus patterns are within Â±3% â€” well within noise. The read path is dominated
   by coodie's ORM overhead (`_rows_to_dicts()`, Pydantic construction), not driver
   overhead.

5. **Serialization is driver-independent**: Model instantiation and serialization
   benchmarks don't touch the database, confirming they measure pure Pydantic
   performance.

6. **For Argus-style real-world patterns**: acsylla shows a slight but consistent
   advantage in multi-step operations (status update âˆ’5%, list mutation âˆ’3%,
   notification feed âˆ’3%), likely due to lower per-operation overhead accumulating
   across multiple CQL calls.

### 9.4 Recommendations

- **Default driver**: Keep scylla-driver as default â€” it has the best overall
  ecosystem support, documentation, and debuggability.
- **acsylla for DDL-heavy workloads**: Applications that frequently call `sync_table`
  (e.g., multi-tenant schemas, dynamic table creation) should consider acsylla.
- **acsylla for LWT-heavy workloads**: Applications using many conditional writes
  (IF NOT EXISTS, IF condition) will see measurable improvement with acsylla.
- **Future**: Once coodie implements `sync_table` caching (Phase 2, task 3.4), the
  DDL advantage of acsylla will be reduced since the cache eliminates repeat calls.

---

## 10. Phase 1 Results

> **Post-optimization run**: [#22371151749](https://github.com/fruch/coodie/actions/runs/22371151749) â€” scylla driver ([job](https://github.com/fruch/coodie/actions/runs/22371151749/job/64752712030?pr=46#step:5:124))
> **PR**: [#46](https://github.com/fruch/coodie/pull/46) â€” `perf: implement Phase 1 performance improvements`

### 10.1 Phase 1 Changes Implemented

| Task | Description | Status |
|------|-------------|--------|
| 3.1 | `_rows_to_dicts()` â€” type-check first row once, fast-path all rows (CassandraDriver) | âœ… Done |
| 3.2 | `@lru_cache` on `_find_discriminator_column()` / `_get_discriminator_value()` | âœ… Done |
| 3.3 | Module-level `get_driver` import in both query.py files | âœ… Done |
| 7.1 | `__slots__` on QuerySet (sync + async), CassandraDriver, AcsyllaDriver, ColumnDefinition | âœ… Done |
| 7.3 | Pydantic `model_config` tuning (`revalidate_instances`, `use_enum_values`, `populate_by_name`) | âœ… Done |
| 7.5 | `_cached_type_hints(cls)` â€” `@lru_cache` wrapper around `get_type_hints()` | âœ… Done |
| 7.7 | `_collection_fields(cls)` â€” pre-compute collection coercion map per class | âœ… Done |
| 7.8 | `model_validate()` instead of `Model(**dict)` in `_rows_to_docs()` | âœ… Done |

**Note**: `extra="forbid"` (Â§7.3) was intentionally omitted â€” materialized views and partial
models read DB rows containing columns not defined in the model, which Pydantic would reject.

### 10.2 Core Operations â€” Before vs After

| Operation | Before (coodie) | After (coodie) | coodie Speedup | Before ratio | After ratio | Î” |
|-----------|----------------|----------------|----------------|--------------|-------------|---|
| **Reads** | | | | | | |
| GET by PK | 1,382 Âµs | 486 Âµs | **âˆ’65%** | 2.12Ã— slower | 0.75Ã— (1.3Ã— faster) | ğŸ†• now beats cqlengine |
| Filter + LIMIT | 3,060 Âµs | 604 Âµs | **âˆ’80%** | 2.73Ã— slower | 0.52Ã— (1.9Ã— faster) | ğŸ†• now beats cqlengine |
| Filter (secondary index) | 18,120 Âµs | 1,555 Âµs | **âˆ’91%** | 4.03Ã— slower | 0.33Ã— (3.0Ã— faster) | ğŸ†• now beats cqlengine |
| COUNT | 1,492 Âµs | 896 Âµs | **âˆ’40%** | 1.46Ã— slower | 0.89Ã— (1.1Ã— faster) | ğŸ†• now beats cqlengine |
| Collection read | 1,405 Âµs | 495 Âµs | **âˆ’65%** | 2.15Ã— slower | 0.74Ã— (1.4Ã— faster) | ğŸ†• now beats cqlengine |
| Collection roundtrip | 2,460 Âµs | 970 Âµs | **âˆ’61%** | 1.89Ã— slower | 0.70Ã— (1.4Ã— faster) | ğŸ†• now beats cqlengine |
| **Writes** | | | | | | |
| Single INSERT | 1,025 Âµs | 451 Âµs | **âˆ’56%** | 1.74Ã— slower | 0.76Ã— (1.3Ã— faster) | ğŸ†• now beats cqlengine |
| INSERT with TTL | 1,016 Âµs | 461 Âµs | **âˆ’55%** | 1.64Ã— slower | 0.76Ã— (1.3Ã— faster) | ğŸ†• now beats cqlengine |
| INSERT IF NOT EXISTS | 2,200 Âµs | 1,469 Âµs | **âˆ’33%** | 1.30Ã— slower | 0.95Ã— (1.1Ã— faster) | ğŸ†• now beats cqlengine |
| Collection write | 1,015 Âµs | 460 Âµs | **âˆ’55%** | 1.62Ã— slower | 0.72Ã— (1.4Ã— faster) | ğŸ†• now beats cqlengine |
| **Updates** | | | | | | |
| Partial UPDATE | 2,203 Âµs | 923 Âµs | **âˆ’58%** | 4.34Ã— slower | 1.72Ã— slower | improved but still slower |
| UPDATE IF condition (LWT) | 3,340 Âµs | 1,823 Âµs | **âˆ’45%** | 2.04Ã— slower | 1.18Ã— slower | improved |
| **Deletes** | | | | | | |
| Single DELETE | 1,970 Âµs | 939 Âµs | **âˆ’52%** | 1.89Ã— slower | 0.87Ã— (1.1Ã— faster) | ğŸ†• now beats cqlengine |
| Bulk DELETE | 2,010 Âµs | 900 Âµs | **âˆ’55%** | 1.72Ã— slower | 0.79Ã— (1.3Ã— faster) | ğŸ†• now beats cqlengine |
| **Batch** | | | | | | |
| Batch INSERT 10 | 3,380 Âµs | 631 Âµs | **âˆ’81%** | 2.02Ã— slower | 0.36Ã— (2.8Ã— faster) | ğŸ†• now beats cqlengine |
| Batch INSERT 100 | 28,612 Âµs | 2,276 Âµs | **âˆ’92%** | 0.54Ã— faster | 0.04Ã— (23.8Ã— faster) | was faster, now dominant |
| **Schema** | | | | | | |
| sync_table create | 2,646 Âµs | 2,508 Âµs | âˆ’5% | 15.3Ã— slower | 14.3Ã— slower | Phase 2 target |
| sync_table no-op | 3,827 Âµs | 3,410 Âµs | âˆ’11% | 17.1Ã— slower | 16.2Ã— slower | Phase 2 target |
| **Serialization (no DB)** | | | | | | |
| Model instantiation | 2.00 Âµs | 2.05 Âµs | â‰ˆ0% | 0.17Ã— (5.8Ã— faster) | 0.17Ã— (5.9Ã— faster) | maintained |
| Model serialization | 2.01 Âµs | 1.94 Âµs | +4% | 0.44Ã— (2.3Ã— faster) | 0.42Ã— (2.4Ã— faster) | maintained |

### 10.3 Argus Real-World Patterns â€” Before vs After

| Pattern | Before (coodie) | After (coodie) | coodie Speedup | Before ratio | After ratio | Î” |
|---------|----------------|----------------|----------------|--------------|-------------|---|
| Batch events (10) | 3,560 Âµs | 1,219 Âµs | **âˆ’66%** | 1.17Ã— slower | 0.40Ã— (2.5Ã— faster) | ğŸ†• now beats cqlengine |
| Comment with collections | 779 Âµs | 531 Âµs | **âˆ’32%** | 1.04Ã— slower | 0.69Ã— (1.4Ã— faster) | ğŸ†• now beats cqlengine |
| Filter by partition key | 1,430 Âµs | 604 Âµs | **âˆ’58%** | 1.34Ã— slower | 0.59Ã— (1.7Ã— faster) | ğŸ†• now beats cqlengine |
| Get-or-create user | 902 Âµs | 497 Âµs | **âˆ’45%** | 1.21Ã— slower | 0.68Ã— (1.5Ã— faster) | ğŸ†• now beats cqlengine |
| Latest N runs (clustering) | 1,188 Âµs | 499 Âµs | **âˆ’58%** | 1.28Ã— slower | 0.52Ã— (1.9Ã— faster) | ğŸ†• now beats cqlengine |
| Multi-model lookup | 1,813 Âµs | 959 Âµs | **âˆ’47%** | 1.37Ã— slower | 0.71Ã— (1.4Ã— faster) | ğŸ†• now beats cqlengine |
| Notification feed | 1,433 Âµs | 600 Âµs | **âˆ’58%** | 1.06Ã— slower | 0.45Ã— (2.2Ã— faster) | ğŸ†• now beats cqlengine |
| List mutation + save | 1,647 Âµs | 997 Âµs | **âˆ’39%** | 2.17Ã— slower | 1.35Ã— slower | improved but still slower |
| Status update | 1,752 Âµs | 956 Âµs | **âˆ’45%** | 2.10Ã— slower | 1.11Ã— slower | improved |
| Argus model instantiation | 18.2 Âµs | 18.1 Âµs | â‰ˆ0% | 0.55Ã— faster | 0.54Ã— faster | maintained |

### 10.4 Success Criteria â€” Phase 1 Scorecard

| Metric | Target | Before | After | Status |
|--------|--------|--------|-------|--------|
| Single INSERT latency | â‰¤ 1.3Ã— cqlengine | 1.74Ã— | **0.76Ã—** | âœ… **Exceeded** â€” now 1.3Ã— faster |
| GET by PK latency | â‰¤ 1.5Ã— cqlengine | 2.12Ã— | **0.75Ã—** | âœ… **Exceeded** â€” now 1.3Ã— faster |
| Filter + LIMIT latency | â‰¤ 1.8Ã— cqlengine | 2.73Ã— | **0.52Ã—** | âœ… **Exceeded** â€” now 1.9Ã— faster |
| `sync_table` no-op | â‰¤ 1.5Ã— cqlengine | 17.1Ã— | **16.2Ã—** | âŒ Not met â€” Phase 2 (table cache) needed |
| Partial UPDATE | â‰¤ 2Ã— cqlengine | 4.34Ã— | **1.72Ã—** | âœ… **Met** |
| Model instantiation | â‰¤ 0.2Ã— (maintain advantage) | 0.17Ã— | **0.17Ã—** | âœ… **Maintained** |
| Model serialization | â‰¤ 0.5Ã— (maintain advantage) | 0.44Ã— | **0.42Ã—** | âœ… **Maintained** |

**6 out of 7 success criteria met or exceeded.** The only unmet target (`sync_table` no-op) requires
Phase 2's table metadata cache, which is a separate feature (not a code optimization).

### 10.5 Key Findings

1. **coodie now beats cqlengine on 24 out of 30 benchmarks.** Before Phase 1, coodie was
   slower than cqlengine on 16 out of 18 DB operations. After Phase 1, coodie is faster on
   all reads, all writes (except partial UPDATE and LWT), all deletes, and all batch operations.

2. **Read operations saw the biggest improvement (40â€“91% faster).** The combination of
   `_cached_type_hints()`, `_rows_to_dicts()` namedtuple fast-path, `_collection_fields()`
   cache, and `model_validate()` eliminated the per-row overhead that dominated read paths.

3. **Batch INSERT 100 improved by 92%** (28.6 ms â†’ 2.3 ms), making coodie **23.8Ã— faster**
   than cqlengine. The `@lru_cache` on discriminator functions eliminated 100Ã— `get_type_hints()`
   calls per batch.

4. **Filter (secondary index) improved by 91%** (18.1 ms â†’ 1.6 ms), going from 4Ã— slower
   to 3Ã— faster than cqlengine. This was the highest-severity bottleneck (ğŸ”´ Critical in Â§1.2).

5. **Argus real-world patterns flipped:** 7 out of 9 DB-backed patterns now beat cqlengine
   (was: 0 out of 9). Only list-mutation and status-update remain slower, both involving
   read-modify-write cycles where the write path still has overhead.

6. **`sync_table` remains the main gap.** Phase 2's table metadata cache (task 3.4) is needed
   to close the 16Ã— overhead on `sync_table` no-op.

7. **Pydantic advantage maintained.** Model instantiation (5.9Ã— faster) and serialization
   (2.4Ã— faster) are unchanged â€” the Phase 1 changes only optimized the ORM â†” driver interface.

### 10.6 Remaining Priorities After Phase 1

| Priority | Task | Expected Impact |
|----------|------|-----------------|
| **P0** | 3.4 Table metadata cache | Close 16Ã— `sync_table` gap â†’ â‰¤ 1.5Ã— |
| P1 | 3.5 Skip column introspection on create | Faster first-run `sync_table` |
| P1 | 3.7 Skip intermediate dict on reads | Further read improvement (already partially done via `model_validate`) |
| P2 | 3.8 CQL query string cache | Eliminate CQL construction overhead |
| P2 | 3.10 Reduce `_clone()` overhead | Faster query chain construction |
| P2 | 7.4 Lazy parsing (LazyDocument) | Near-zero cost for PK-only reads |

---

## 11. Phase 2 Results

### 11.1 Phase 2 Changes Implemented

| Task | Description | Status |
|------|-------------|--------|
| 3.4 | `_known_tables` cache on both CassandraDriver and AcsyllaDriver â€” second `sync_table` call is a no-op | âœ… Done |
| 3.5 | Skip ALTER TABLE when existing columns already match model columns (new table) | âœ… Done |

### 11.2 Phase 2 Design

**Task 3.4 â€” Table metadata cache:**
- Added `_known_tables: set[str]` to `__slots__` on both `CassandraDriver` and `AcsyllaDriver`.
- On `sync_table()` / `sync_table_async()`, the driver first checks `f"{keyspace}.{table}"` in `_known_tables`.
- On cache hit: returns immediately (zero CQL queries).
- On cache miss: runs the full sync flow, then adds the key to `_known_tables`.
- The cache is per-driver-instance and lives for the session lifetime â€” no stale data across restarts.

**Task 3.5 â€” Skip column introspection on create:**
- After `CREATE TABLE IF NOT EXISTS`, the driver introspects `system_schema.columns` to get existing columns.
- If the existing column set matches the model's column set exactly, the table was just created with all columns â€” `ALTER TABLE ADD` is skipped entirely.
- For tables with extra DB-side columns (e.g., schema drift), the existing ALTER TABLE logic still runs.

### 11.3 Remaining Priorities After Phase 2

| Priority | Task | Expected Impact |
|----------|------|-----------------|
| P1 | 3.7 Skip intermediate dict on reads | Further read improvement |
| P2 | 3.8 CQL query string cache | Eliminate CQL construction overhead |
| P2 | 3.10 Reduce `_clone()` overhead | Faster query chain construction |
| P2 | 7.4 Lazy parsing (LazyDocument) | Near-zero cost for PK-only reads |

---

## 12. Notes

- coodie's Pydantic-based model system is **already 5.8Ã— faster** than cqlengine for
  pure Python model construction. The overhead is in the ORM â†” driver interface.
- **New finding**: coodie's batch INSERT for 100 rows is **1.9Ã— faster** than cqlengine,
  likely because `build_batch()` constructs CQL more efficiently than cqlengine's
  per-statement batch approach.
- The biggest single improvement is task 3.4 (table cache) â€” it eliminates the
  **17Ã— overhead** on `sync_table` with minimal code change.
- Tasks 3.1 and 3.7 together can significantly reduce read latency by eliminating
  unnecessary dict conversions.
- The filter-secondary-index benchmark (4.0Ã— slower) likely includes Pydantic model
  construction overhead for multiple rows â€” task 3.7 directly addresses this.
- Tasks 7.1 (`__slots__`) and 7.5 (type hints cache) are low-risk, high-reward
  changes that can be done first as they require no API changes.
- Beanie's `lazy_parse` and `projection_model` patterns are powerful but require
  API additions â€” schedule for Phase 3 after core performance is optimized.
- **Argus patterns show coodie is close to parity**: 6 out of 9 DB-backed Argus
  benchmarks are within 1.4Ã— of cqlengine. Only write-heavy patterns (list mutation,
  status update) show significant overhead, confirming the write-path optimization
  priorities in Phases 1 and 3.
